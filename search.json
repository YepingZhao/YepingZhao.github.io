[{"path":"/2025/07/02/Transformers are Graph Neural Networks/","content":"Chaitanya K. Joshi 证明了 Transformer 架构在数学上等同于在全连接图上运行的图神经网络 (GNN)。这项工作解释了 Transformer 的经验成功部分归因于其通过密集矩阵运算实现的效率，这些运算针对现代硬件进行了高度优化，这与传统 GNN 通常的稀疏运算形成对比。 目录 引言 Transformer架构与自注意力机制 图神经网络与消息传递 建立形式等价性 硬件彩票假说 图 Transformers 和混合方法 对架构设计的影响 灵活性和归纳偏置 结论 相关引用 引言随着深度学习领域寻求从经验观察转向原则性设计，理解成功深度学习架构的理论基础变得越来越重要。剑桥大学的Chaitanya K. Joshi撰写的这篇论文提供了一项严谨的数学分析，论证了Transformer——自然语言处理领域的主导架构，并日益应用于计算机视觉领域——在根本上等同于在全连接图上操作的图神经网络（GNN）。 核心论点在于，Transformer中的自注意力机制可以被理解为GNN中消息传递的一个特定实例，其中每个词元都关注其他所有词元，这构成了一个完整的图结构。这种理论联系不仅为Transformer为何如此有效提供了新见解，还通过作者所称的“硬件彩票”——即它们与现代并行计算架构的对齐——解释了它们的实际主导地位。 图1：从顺序RNN处理到Transformer中全连接注意力机制的演进，展示了Transformer如何同时而非顺序地处理所有词元。 Transformer架构与自注意力机制论文首先建立了Transformer架构的数学基础，特别关注构成其计算核心的自注意力机制。在Transformer中，每个输入词元通过学习的线性投影转换为三个向量：查询（Q）、键（K）和值（V）表示。 位置 $i$ 的词元关注序列 $\\mathcal{S}$ 中所有词元的自注意力操作计算如下： $$h_i^{\\ell+1} \\sum_{j \\in \\mathcal{S}} \\text{softmax}_j\\left(\\frac{Q^{\\ell}_i \\cdot K^{\\ell}_j}{\\sqrt{d_k}}\\right) V^{\\ell}_j$$ 其中softmax归一化确保注意力权重在所有位置上总和为一。这种公式允许每个词元潜在地关注序列中的其他所有词元，从而创建一种全连接的注意力模式。 多头注意力通过并行计算多个注意力模式来扩展这一概念，每个模式侧重于词元之间关系的不同方面。所有注意力头的输出被连接起来，并通过额外的层，包括残差连接、层归一化和词元级前馈网络。 图神经网络与消息传递论文随后全面概述了图神经网络，强调了它们在消息传递框架中的基础。GNN在图结构数据上操作，信息通过三个基本操作在连接的节点之间传播： 消息构建 ：使用函数 $\\psi$ 计算连接节点之间的消息。 消息聚合 ：使用聚合函数 $\\Psi$ 组合来自邻近节点的消息。 节点更新 ：使用函数 $\\phi$ 更新节点表示。 通用的消息传递更新可以表示为： $$h_i^{\\ell+1} \\phi\\left(h_i^{\\ell}, \\Psi_{j \\in \\mathcal{N}(i)} \\psi(h_i^{\\ell}, h_j^{\\ell})\\right)$$ 其中 $\\mathcal{N}(i)$ 表示根据图结构节点 $i$ 的邻域。这个框架包含了许多流行的GNN变体，包括图卷积网络和图注意力网络（GATs）。 建立形式等价性论文的核心贡献在于通过详细映射它们的计算操作，证明了Transformer与GNN之间的数学等价性。关键的见解是，Transformer自注意力作为在完整图上的消息传递操作，其中每个词元都与其他所有词元相连接。 在此映射中： 词元成为节点 ：每个输入词元都对应于一个全连接图中的节点 自注意力成为消息传递 ：Query-Key-Value 计算直接对应于消息的构建和聚合 注意力权重成为边权重 ：经过 softmax 归一化的注意力分数决定了消息的重要性 将注意力计算与图注意力网络（GATs）进行比较时，这种等价性变得显而易见，GATs 使用注意力机制来加权来自邻居节点的消息： $$\\text{Transformer attention} \\equiv \\text{GAT on complete graph}$$ 这意味着，虽然 GATs 只对图中定义的邻居应用注意力，但 Transformers 对所有位置全局应用注意力，有效地将输入视为一个完全图。 硬件彩票假说在建立理论等价性的同时，这篇论文解决了一个关键的实际问题：如果 Transformers 和 GNNs 在根本上是相似的，为什么 Transformers 取得了如此广泛的成功和可扩展性？答案在于作者所谓的“硬件彩票”。 Transformers 通过密集矩阵运算实现其全局注意力，这些运算针对现代并行计算硬件（GPU 和 TPU）进行了高度优化。自注意力计算可以利用优化的 BLAS（基本线性代数子程序）操作进行高效并行化，使其计算速度极快。 相比之下，传统的 GNNs 依赖于稀疏的消息传递操作，这些操作涉及在不规则图结构上的 gather-scatter 计算。这些操作在当前的硬件架构上效率较低，导致训练速度较慢和扩展困难。 Transformers 中的数学运算可以表示为： $$\\text{Attention}(Q,K,V) \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$ 这种公式利用了高度优化的密集矩阵乘法，而等效的 GNN 操作通常需要在图邻接结构上进行效率较低的稀疏计算。 图 Transformers 和混合方法Transformers 和 GNNs 之间的理论联系启发了图 Transformers 的发展，这些模型旨在结合两种方法的优点。这些模型试图整合显式的图结构（传统 GNNs 的归纳偏置），同时保持 Transformers 的全局注意力能力和计算效率。 图 Transformers 通常修改注意力机制以尊重图结构，方法包括仅对图定义的邻居进行注意力遮蔽，或将图距离整合到注意力计算中。这使得它们能够扩展到更大的图，同时保持结构感知能力。 对架构设计的影响本文揭示的等价性对未来的架构设计具有几个重要意义。首先，它表明 Transformers 的成功不仅源于其表达能力，还在于它们与现有计算硬件的契合。这一见解强调了在设计新架构时，除了理论能力外，还要考虑硬件效率的重要性。 其次，这种联系为开发混合模型提供了原则性基础，这些模型结合了局部结构偏置（来自 GNNs）和全局注意力机制（来自 Transformers）。这可能为图结构数据带来更高效的模型，同时保持 Transformers 的可扩展性优势。 灵活性和归纳偏置Transformer-GNN 等价性的一个重要方面是它如何阐明了灵活性和归纳偏置之间的权衡。传统的 GNNs 通过其图连接模式，嵌入了关于数据关系的强烈结构假设。Transformers 在完全图上操作，进行较少的结构假设，并且可以直接从数据中学习关系。 这种灵活性使得Transformer能够发现复杂的、长程依赖关系，这些关系可能无法被预定义的图结构捕获。然而，这也意味着它们可能需要更多的数据和计算量来学习那些可以通过专用架构中适当的归纳偏置高效编码的模式。 结论本文通过形式化地确立Transformer与图神经网络之间的等价性，揭示了这些看似不同的架构共享基本计算原理，从而做出了重要的理论贡献。Transformer本质上是在全连接图上运行的GNN这一关键洞察，为两种架构都提供了新的视角。 关于Transformer在实践中占据主导地位的“硬件彩票”解释，为理解计算限制如何塑造不同架构的采用提供了一个令人信服的框架。这项分析表明，成功的深度学习模型不仅要根据其理论表达能力进行评估，还要根据其与可用计算资源的契合度进行评估。 此处提出的理论统一性为研究开辟了新途径，特别是在开发结合GNN结构感知能力与Transformer计算效率的图Transformer方面。随着该领域继续寻求更通用、更高效的架构，这种对不同模型家族之间关系的原则性理解，对于指导未来的发展可能会变得越来越有价值。 相关引用注意力就是你所需要的一切 本文介绍了Transformer架构，该架构是所比较的两种主要架构之一。主论文的核心论点在于重新解读Transformer的机制，特别是其多头注意力机制，使其成为一个奠基性参考文献。 A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in neural information processing systems, 2017. 图注意力网络 这篇论文至关重要，因为它引入了图注意力网络 (GATs)。作者提出了 Transformer 的自注意力机制与 GATs 中的注意力机制之间直接且形式上的等价性，这构成了 Transformer 是一种图神经网络 (GNN) 这一论证的核心支柱。 P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Liò, and Y. Bengio. Graph Attention Networks. ICLR, 2018. 关系归纳偏置、深度学习与图网络 本文提供了图神经网络的通用消息传递框架。作者利用这一形式化方法，展示了 Transformer 的操作如何能完美地在消息传递范式中描述，从而在理论层面建立了联系。 P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint, 2018. 硬件彩票 这篇引文是该论文结论的核心。在确立了数学等效性之后，作者利用“硬件彩票”概念来解释为什么Transformer比传统GNN更具主导地位，认为这是因为其架构在现代并行硬件（如GPU）上表现出卓越的效率。 S. Hooker. The hardware lottery. Communications of the ACM, 2021.","tags":["alphaXiv"],"categories":["文献阅读笔记","alphaXiv"]},{"title":"Git","path":"/2025/07/02/Git/","content":"配置检查 SSH基本使用","tags":["Git"],"categories":["命令行工具","Git"]},{"title":"My New Post","path":"/2025/07/02/My-New-Post/","content":"暂时无法在飞书文档外展示此内容 nohupnohup 后台启动-综合使用 后台执行test.sh文件，将标准日志输出到output.log文件中，将错误日志也输出到output.log文件中nohup .test.sh output.log 21 等同于nohup .test.sh output.log 2output.log pythonnohup python .train.py train.log 21 nohup 后台启动(不生成日志)#devnull 表示空设备文件。 如果不想输出任何的日志时，使用此参数 。nohup .test.sh devnull 不停止服务，直接清空 nohup.out 第1种：cat devnull nohup.out 第2种：cp devnull nohup.outGitGit 初始化配置 a、设置用户名：git config –global user.name “用户名” b、设置用户邮箱：注意：该配置会在github主页上显示谁提交了该文件git config –global user.email “电子邮件” c、配置ok之后，我们用如下命令来看看是否配置成功git config –list测试 SSH 连接ssh -T kill 查找占用23456端口的进程sudo lsof -i :23456 杀死相关进程sudo kill -9 apt 进入目录cd ~Downloads 用 apt 安装（首选）sudo apt install .your-package.deb 如果报错则修复依赖sudo apt –fix-broken install 验证安装dpkg -l | grep package-name tree安装sudo apt-get install tree # UbuntuDebian 系统brew install tree # macOS常见选项介绍 -s 选项：显示文件大小tree -s . -h 选项：以人类可读的格式显示大小tree -sh 2 . -L 选项：限制显示层级tree -L 2 . -f 选项：显示完整路径tree -f . -a 选项：包括隐藏文件tree -a . tar 解压分卷压缩的 feat.tar.gz.00 到 feat.tar.gz.31 文件cat feats.tar.gz.* | tar -xzvf - PowerShell 更新 步骤一：检查当前版本$PSVersionTable.PSVersion步骤二：搜索最新版本的 PowerShellwinget search Microsoft.PowerShell步骤三：安装新版本 使用 Winget 安装 PowerShellwinget install –id Microsoft.Powershell –source winget 使用 Winget 安装 PowerShell 预览版winget install –id Microsoft.Powershell.Preview –source winget步骤四：验证更新$PSVersionTable.PSVersion rsync使用 rsync 进行文件传输时，目标路径的结尾斜杠不会影响传输行为，而源路径末尾是否有斜杠则会影响传输行为源路径末尾有斜杠，如 zhao，会将源路径目录中的子文件递归传输到目标路径源路径末尾无斜杠，如 zhao，会将源路径目录及其子文件递归传输到目标路径 -P：等价于 –partial –progress–partial：保留部分传输的文件（实现断点续传）–progress：显示实时传输进度-a：归档模式（保留权限、时间戳等）-v：详细输出模式-z：压缩传输数据（节省带宽）有斜杠rsync -avzP –progress samsungzhao :homeuesrzhaobackup 无斜杠rsync -avzP –progress samsungzhao :homeuesrzhaobackup du❯ du -sh samsungzhao1.4T samsungzhao ❯ du -sh samsungzhaomedia_data647G samsungzhaomedia_data ❯ du -sh samsungzhaohuggingface72G samsungzhaohuggingface ❯ du -sh samsungzhaogithub435G samsungzhaogithub update-alternatives update-alternatives: –install 链接 名称 路径 优先级sudo update-alternatives –install usrbinjava java usrlibjvmjdk1.8.0_202binjava 2 查看已注册的备选方案update-alternatives –list java # 查看所有可选的 Java 版本 或查看所有管理的命令:update-alternatives –get-selections 切换版本sudo update-alternatives –config java 查看sudo update-alternatives –display cuda cudasudo update-alternatives –install usrlocalcuda cuda usrlocalcuda-12.4 50 gccsudo update-alternatives –install usrbingcc gcc usrbingcc-12 2 g++sudo update-alternatives –install usrbing++ g++ usrbing++-11 1 Todesk 重启sudo systemctl restart todeskd 安装 cudnntar -zxvf cudnn-10.1-linux-x64-v7.6.5.32.tgz sudo cp cudaincludecudnn.h usrlocalcudaincludesudo cp cudalib64libcudnn* usrlocalcudalib64sudo chmod a+r usrlocalcudaincludecudnn.hsudo chmod a+r usrlocalcudalib64libcudnn*CUDA 版本管理 方法一：使用update-alternatives（推荐）这是最优雅的方式，可以系统级管理多个CUDA版本。 在 ~.bashrc 和 ~.zshrc 中添加下面的配置export PATHusrlocalcudabin:$PATHexport LD_LIBRARY_PATHusrlocalcudalib64:$LD_LIBRARY_PATH 首先为每个CUDA版本注册到alternatives系统：sudo update-alternatives –install usrlocalcuda cuda usrlocalcuda-11.3 100sudo update-alternatives –install usrlocalcuda cuda usrlocalcuda-10.2 50这里的数字是优先级，数字越大优先级越高。 查看已注册的CUDA版本：sudo update-alternatives –config cuda你会看到类似这样的输出：There are 2 choices for the alternative cuda (providing usrlocalcuda).Selection Path Priority Status0 usrlocalcuda-11.3 100 auto mode 1 usrlocalcuda-10.2 50 manual mode 2 usrlocalcuda-11.3 100 manual modePress to keep the current choice[*], or type selection number:4. 输入对应的数字选择要使用的版本，然后按回车。5. 验证当前CUDA版本切换后，验证当前使用的CUDA版本：nvcc –version输出类似：nvcc: NVIDIA (R) Cuda compilerCopyright (c) 2005-2021 NVIDIA CorporationBuilt on Sun_Mar_21_19:15:46_PDT_2021Cuda compilation tools, release 11.3, V11.3.58Build cuda_11.3.r11.3compiler.29745058_0Ubuntudevnwme0n1p2: clean, 243946197648640 files, 371046884390572032 blocks解决 Linux 桌面问题思路分享 - 学习日记ubuntu 黑屏 进入不了图形界面 devsda1: clean, 5525996111232 files, 711929524414464 blocks_ubuntu只有黑窗口-CSDN博客Hexo手把手教你搭建 Hexo 博客 - webfem如何用Hexo搭建个人博客?运行 Hexo 服务器hexo serverhexo clean # 清除缓存文件等hexo g # 生成页面hexo s # 启动预览 部署到 GitHubhexo g # 生成页面hexo d # 部署发布安装 hexo-deployer-gitnpm install hexo-deployer-git –save修改 _config.yml 修改 _config.yml 文件末尾的 Deployment 部分deploy: type: git repository: :用户名用户名.github.io.git branch: mainhttps://YepingZhao.github.iohexo new “My New Post”hexo g hexo d扩展及插件添加文章的字数统计下载插件：npm install hexo-symbols-count-time –save然后打开根目录的配置文件，复制粘贴以下内容：symbols_count_time: 每篇文章显示 symbols: true time: true 文章底部显示 totalsymbols: false totaltime: false 是否统计代码块 exclude_codeblock: false awl: 2 wpm: 275 suffix: “mins.”XUI + x2rayN一、访问 xray 面板1、浏览器访问 xray 面板浏览器输入网址访问 xray 面板网址：http://66.112.218.20:21000/EduR/xui/[图片] 2、系统登录输入用户名、密码登入系统。用户名：admin密码：admin123[图片] 3、复制入站信息选中左侧菜单栏中的 “入站列表”，选中其中任一入站URL，根据图示流程操作，复制入站URL信息。[图片][图片] 二、x2rayN1、导入入站 URL 信息打开本地 x2rayN，根据图示流程操作，导入入站URL信息。[图片] 2、启用服务器 URL右键选中 x2rayN 列表中的服务器，单击 “设为活动服务器” 选项，观察到选中活动服务器切换为紫色背景，即服务器启用成功。可以打开浏览器访问油管（YouTube），验证服务是否成功启用。[图片]"},{"title":"Hello World","path":"/2025/07/02/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new My New Post More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment 标题1标题2标题3标题4标题5 列表1 列表2 有序列表1 有序列表2 引用引用引用","tags":["iOS","心率"],"categories":["设计开发","iOS开发"]}]